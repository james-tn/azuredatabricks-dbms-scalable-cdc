# azuredatabricks-dbms-scalable-cdc
Scalable CDC from DBMS to Azure Databricks

Summary of algorithm
- CDC program send change data from various tables into ADLS Gen 2 folder, each table has its own folder. 
- Each change data file will come with a schema file (dfm) that describe the schema of the data file
- Azure Eventgrid listen to new files landed in the subscribed folder and create messages  detailing locations and type of operations for each file
- Our main program will read messages from message queue, sort them by table then process messages in batch with a predefined size. By sorting we will have least number of table possible in each batch
- Within each batch, the process_files program will group by table and retrieve a unique schema file and data files for each table in the group by. From schema file, it will form the schema and use it to retrieve data  
- For insert data, use regular insert. For update and delete, user MERGE to merge data to target table

Libraries: Please install azure-storage-queue and azure to Databricks cluster

Data: We use a sample CDC files generated by Attunity. Please upd]ate the sample data to folder where each folder represents a landing location for a table.

Configuring Azure Eventgrid and Storage Queue

https://docs.microsoft.com/en-us/azure/event-grid/custom-event-to-queue-storage

1. Setup Event subscription in your storage account
2. Route the event to a Storage Queue 
